{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b77baa7e-07d8-4013-ba89-15f6f482bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingsound import (\n",
    "    TrainingArguments,\n",
    "    ModelArguments,\n",
    "    SpeechRecognitionModel,\n",
    "    TokenSet,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a618e5e9",
   "metadata": {},
   "source": [
    "# Log into HuggingFace Hub\n",
    "\n",
    "Run the following cell and enter the HuggingFace Hub token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24075f",
   "metadata": {},
   "source": [
    "Pull the model from the Hub into the local model directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repository(local_dir=\"models/\", clone_from=\"mfreihaut/finetuned-audio-transcriber\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab87ae3",
   "metadata": {},
   "source": [
    "The following cell isn't yet working as intended. It should load the model that was just pulled from the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f1346de-df90-4219-b2c8-d1615ee0954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/10/2022 12:50:11 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/mfreihaut/finetuned-audio-transcriber/resolve/main/config.json from cache at /Users/matthewfreihaut/.cache/huggingface/transformers/23a11cbcb2f1369c646374f1e3565046951bb0ac9de5bcf1ff352b00474e25e5.a1565b600b9ce478dd180f83cbc859637902cd846c02e0c35b38e5bef5cb4bbd\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"mfreihaut/finetuned-audio-transcriber\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 27,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/mfreihaut/finetuned-audio-transcriber/resolve/main/pytorch_model.bin from cache at /Users/matthewfreihaut/.cache/huggingface/transformers/b962d734fd6019760c029275ddd1ee79a146cf6637431af047cc61bf4688fb01.a43f4e4c64f8bf3870157221bb1f473a0fb37615fcaaff04c131df1066b6b027\n",
      "All model checkpoint weights were used when initializing Wav2Vec2ForCTC.\n",
      "\n",
      "All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at mfreihaut/finetuned-audio-transcriber.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.\n",
      "loading feature extractor configuration file https://huggingface.co/mfreihaut/finetuned-audio-transcriber/resolve/main/preprocessor_config.json from cache at /Users/matthewfreihaut/.cache/huggingface/transformers/847ffef7f9ed63d0695ea0394ab391ceadfb2f42d4824febc34702e491e493b7.05dd4b7fb2fcf1b06199659df402b7970da0ab89461d00e9df6d488767acf7dc\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"processor_class\": \"Wav2Vec2Processor\",\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/mfreihaut/finetuned-audio-transcriber/resolve/main/vocab.json from cache at /Users/matthewfreihaut/.cache/huggingface/transformers/751fa9813c990996e01ee05238bc309d87da8ab8aa995b019c36794e2b123f54.77b6cbee47ea4c93493e27bccee89204463b2d558318d38ef70373d1e5606c29\n",
      "loading file https://huggingface.co/mfreihaut/finetuned-audio-transcriber/resolve/main/tokenizer_config.json from cache at /Users/matthewfreihaut/.cache/huggingface/transformers/ba25d46781bab914b68d83d48d81ee211c2abf8b3009af76de72c322c23f4c5e.373aa3f15e9097fde5262d2391793182c9fa54c5df2e6072302a500f60cd64f0\n",
      "loading file https://huggingface.co/mfreihaut/finetuned-audio-transcriber/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/mfreihaut/finetuned-audio-transcriber/resolve/main/special_tokens_map.json from cache at /Users/matthewfreihaut/.cache/huggingface/transformers/106535828501a30fd899fcc5c2409997e4dc0ebb8b86c8a0d9e95a0de79c260e.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    model = SpeechRecognitionModel(\"mfreihaut/finetuned-audio-transcriber\")\n",
    "except:\n",
    "    model = SpeechRecognitionModel(\"facebook/wav2vec2-large-xlsr-53\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b69f43d-cc91-4e63-82b3-41519375abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    \"a\",\n",
    "    \"b\",\n",
    "    \"c\",\n",
    "    \"d\",\n",
    "    \"e\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"h\",\n",
    "    \"i\",\n",
    "    \"j\",\n",
    "    \"k\",\n",
    "    \"l\",\n",
    "    \"m\",\n",
    "    \"n\",\n",
    "    \"o\",\n",
    "    \"p\",\n",
    "    \"q\",\n",
    "    \"r\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"u\",\n",
    "    \"v\",\n",
    "    \"w\",\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"z\",\n",
    "    \"'\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0181915f-71b2-41e6-8159-e1dc3e23bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/10/2022 12:28:31 - WARNING - root - blank_token <pad> not in provided tokens. It will be added to the list of tokens\n",
      "06/10/2022 12:28:31 - WARNING - root - silence_token | not in provided tokens. It will be added to the list of tokens\n",
      "06/10/2022 12:28:31 - WARNING - root - unk_token <unk> not in provided tokens. It will be added to the list of tokens\n",
      "06/10/2022 12:28:31 - WARNING - root - bos_token <s> not in provided tokens. It will be added to the list of tokens\n",
      "06/10/2022 12:28:31 - WARNING - root - eos_token </s> not in provided tokens. It will be added to the list of tokens\n"
     ]
    }
   ],
   "source": [
    "token_set = TokenSet(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f7ce44-7357-43ad-bdc0-c0e687d8903e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining_args = TrainingArguments(\\n    learning_rate=3e-4,\\n    max_steps=1000,\\n    eval_steps=200,\\n    per_device_train_batch_size=2,\\n    per_device_eval_batch_size=2,\\n    overwrite_output_dir=True,\\n    \\n    \\n)\\nmodel_args = ModelArguments(\\n    activation_dropout=0.1,\\n    hidden_dropout=0.1,\\n) \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=3e-4,\n",
    "    max_steps=1000,\n",
    "    eval_steps=200,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    \n",
    ")\n",
    "model_args = ModelArguments(\n",
    "    activation_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    ") \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77f9a5",
   "metadata": {},
   "source": [
    "# Model Fine Tuning\n",
    "\n",
    "To fine tune our audio transcription model, provide the audio file and the transcriptions of the audio file in a list of dicts format   \n",
    "`[{\n",
    "        \"path\": '/Users/matthewfreihaut/Downloads/test_audio.mp3',\n",
    "        \"transcription\": 'The quick brown fox jumps over the lazy dog',\n",
    "    },]`\n",
    "\n",
    "The models directory needs to be emptied before running the fine tuning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6e637b-5f75-4d16-a174-511f71d89874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/10/2022 12:35:57 - WARNING - huggingsound.speech_recognition.model - The model is already fine-tuned. So the provided token_set won't be used. The model's token_set will be used instead\n",
      "06/10/2022 12:35:57 - INFO - huggingsound.speech_recognition.model - Loading training data...\n",
      "06/10/2022 12:35:57 - INFO - huggingsound.speech_recognition.model - Converting data format...\n",
      "06/10/2022 12:35:57 - INFO - huggingsound.speech_recognition.model - Preparing data input and labels...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54421cb016a04451b615b39fe67cc1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/10/2022 12:35:57 - INFO - huggingsound.speech_recognition.model - Starting fine-tuning process...\n",
      "06/10/2022 12:35:57 - INFO - huggingsound.trainer - Getting dataset stats...\n",
      "06/10/2022 12:35:57 - INFO - huggingsound.trainer - Training dataset size: 1 samples, 0.00202 hours\n",
      "06/10/2022 12:36:01 - INFO - huggingsound.trainer - Building trainer...\n",
      "06/10/2022 12:36:01 - INFO - huggingsound.trainer - Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1674: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  warnings.warn(\n",
      "Feature extractor saved in models/preprocessor_config.json\n",
      "tokenizer config file saved in models/tokenizer_config.json\n",
      "Special tokens file saved in models/special_tokens_map.json\n",
      "The following columns in the training set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: length. If length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732f1aafe8804f68b6c23f0799307ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to models/\n",
      "Configuration saved in models/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 47.2207, 'train_samples_per_second': 0.064, 'train_steps_per_second': 0.064, 'train_loss': 897.8904622395834, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  train_loss               =   897.8905\n",
      "  train_runtime            = 0:00:47.22\n",
      "  train_samples            =          1\n",
      "  train_samples_per_second =      0.064\n",
      "  train_steps_per_second   =      0.064\n",
      "06/10/2022 12:36:50 - INFO - huggingsound.speech_recognition.model - Loading fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"models/\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 27,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file models/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing Wav2Vec2ForCTC.\n",
      "\n",
      "All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at models/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.\n",
      "loading feature extractor configuration file models/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"processor_class\": \"Wav2Vec2Processor\",\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/added_tokens.json. We won't load it.\n",
      "loading file models/vocab.json\n",
      "loading file models/tokenizer_config.json\n",
      "loading file None\n",
      "loading file models/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"models/\"\n",
    "\n",
    "train_data = [\n",
    "    {\n",
    "        \"path\": '/Users/matthewfreihaut/Downloads/test_audio.mp3',\n",
    "        \"transcription\": 'The quick brown fox jumps over the lazy dog',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "model.finetune(\n",
    "    output_dir,\n",
    "    train_data=train_data,\n",
    "    token_set=token_set,\n",
    "    \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fef65f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f089fc9-3b81-40ca-b4ca-26711dc85bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "794a38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
      "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
      "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
      "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
      "Initialized empty Git repository in /Users/matthewfreihaut/Projects/MLOps_project/model_refinement/.git/\n"
     ]
    }
   ],
   "source": [
    "! git init && git remote add origin \"mfreihaut/finetuned-audio-transcriber\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55d906d0-93f6-49e5-827b-0cacf9835bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/mfreihaut/finetuned-audio-transcriber into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/10/2022 12:51:10 - WARNING - huggingface_hub.repository - Cloning https://huggingface.co/mfreihaut/finetuned-audio-transcriber into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfa75f4a3264db696e8135f0482915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 2.13k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82b1fc0296d4e289fdce8ed918ab79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13506cf25fe441568f3c6b76ac8d06cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  34%|###4      | 1.00k/2.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47464d905e84f1f914ae498dc2ff62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repo = Repository(local_dir=\"models/\", clone_from=\"mfreihaut/finetuned-audio-transcriber\")\n",
    "\n",
    "#finetuned-audio-transcriber\n",
    "\n",
    "#repo.git_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af5f3211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x7f7908fbf160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.commit(commit_message=\"Model refinements made\", blocking=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b516be4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not find a tracked remote branch, please specify <upstream> manually.\nusage: git cherry [-v] [<upstream> [<head> [<limit>]]]\n\n    --abbrev[=<n>]        use <n> digits to display object names\n    -v, --verbose         be verbose\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py:303\u001b[0m, in \u001b[0;36mcommits_to_push\u001b[0;34m(folder, upstream)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=301'>302</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=302'>303</a>\u001b[0m     result \u001b[39m=\u001b[39m run_subprocess(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgit cherry -v \u001b[39;49m\u001b[39m{\u001b[39;49;00mupstream \u001b[39mor\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49msplit(), folder)\n\u001b[1;32m    <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=303'>304</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py:51\u001b[0m, in \u001b[0;36mrun_subprocess\u001b[0;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=48'>49</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run_subprocess` should be called with a list of strings.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=51'>52</a>\u001b[0m     command,\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=52'>53</a>\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=53'>54</a>\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=54'>55</a>\u001b[0m     check\u001b[39m=\u001b[39;49mcheck,\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=55'>56</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=56'>57</a>\u001b[0m     cwd\u001b[39m=\u001b[39;49mfolder,\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=57'>58</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/utils/_subprocess.py?line=58'>59</a>\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aws_fastapi/lib/python3.8/subprocess.py:516\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/subprocess.py?line=514'>515</a>\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[0;32m--> <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/subprocess.py?line=515'>516</a>\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[1;32m    <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/subprocess.py?line=516'>517</a>\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m    <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/subprocess.py?line=517'>518</a>\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'cherry', '-v']' returned non-zero exit status 129.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewfreihaut/Projects/MLOps_project/model_refinement.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matthewfreihaut/Projects/MLOps_project/model_refinement.ipynb#ch0000014?line=0'>1</a>\u001b[0m repo\u001b[39m.\u001b[39;49mgit_push()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py:1119\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=1115'>1116</a>\u001b[0m \u001b[39mif\u001b[39;00m upstream:\n\u001b[1;32m   <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=1116'>1117</a>\u001b[0m     command \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m --set-upstream \u001b[39m\u001b[39m{\u001b[39;00mupstream\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=1118'>1119</a>\u001b[0m number_of_commits \u001b[39m=\u001b[39m commits_to_push(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_dir, upstream)\n\u001b[1;32m   <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=1120'>1121</a>\u001b[0m \u001b[39mif\u001b[39;00m number_of_commits \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=1121'>1122</a>\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=1122'>1123</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeveral commits (\u001b[39m\u001b[39m{\u001b[39;00mnumber_of_commits\u001b[39m}\u001b[39;00m\u001b[39m) will be pushed upstream.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=1123'>1124</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py:306\u001b[0m, in \u001b[0;36mcommits_to_push\u001b[0;34m(folder, upstream)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=303'>304</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=304'>305</a>\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> <a href='file:///Users/matthewfreihaut/opt/anaconda3/envs/aws_fastapi/lib/python3.8/site-packages/huggingface_hub/repository.py?line=305'>306</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(exc\u001b[39m.\u001b[39mstderr)\n",
      "\u001b[0;31mOSError\u001b[0m: Could not find a tracked remote branch, please specify <upstream> manually.\nusage: git cherry [-v] [<upstream> [<head> [<limit>]]]\n\n    --abbrev[=<n>]        use <n> digits to display object names\n    -v, --verbose         be verbose\n\n"
     ]
    }
   ],
   "source": [
    "repo.git_push()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fff4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Parent</th>\n",
       "      <th>Name</th>\n",
       "      <th>Tier 1</th>\n",
       "      <th>Tier 2</th>\n",
       "      <th>Tier 3</th>\n",
       "      <th>Tier 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Auto Body Styles</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Auto Body Styles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Commercial Trucks</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Auto Body Styles</td>\n",
       "      <td>Commercial Trucks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Auto Body Styles</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Station Wagon</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Auto Body Styles</td>\n",
       "      <td>Station Wagon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>698</td>\n",
       "      <td>j9PaO9</td>\n",
       "      <td>v9i3On</td>\n",
       "      <td>Obscenity and Profanity</td>\n",
       "      <td>Sensitive Topics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>699</td>\n",
       "      <td>pg0WhF</td>\n",
       "      <td>v9i3On</td>\n",
       "      <td>Illegal Drugs/Tobacco/eCigarettes/ Vaping/Alcohol</td>\n",
       "      <td>Sensitive Topics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>700</td>\n",
       "      <td>6i4dB6</td>\n",
       "      <td>v9i3On</td>\n",
       "      <td>Spam or Harmful Content</td>\n",
       "      <td>Sensitive Topics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>701</td>\n",
       "      <td>8FD8nI</td>\n",
       "      <td>v9i3On</td>\n",
       "      <td>Terrorism</td>\n",
       "      <td>Sensitive Topics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>702</td>\n",
       "      <td>Z7rJBM</td>\n",
       "      <td>v9i3On</td>\n",
       "      <td>Debated Sensitive Social Issues</td>\n",
       "      <td>Sensitive Topics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>703 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 Unique ID   Parent  \\\n",
       "0             0          1     NaN   \n",
       "1             1          2       1   \n",
       "2             2          3       2   \n",
       "3             3          4       2   \n",
       "4             4          5       2   \n",
       "..          ...        ...     ...   \n",
       "698         698     j9PaO9  v9i3On   \n",
       "699         699     pg0WhF  v9i3On   \n",
       "700         700     6i4dB6  v9i3On   \n",
       "701         701     8FD8nI  v9i3On   \n",
       "702         702     Z7rJBM  v9i3On   \n",
       "\n",
       "                                                  Name            Tier 1  \\\n",
       "0                                           Automotive        Automotive   \n",
       "1                                     Auto Body Styles        Automotive   \n",
       "2                                    Commercial Trucks        Automotive   \n",
       "3                                                Sedan        Automotive   \n",
       "4                                        Station Wagon        Automotive   \n",
       "..                                                 ...               ...   \n",
       "698                            Obscenity and Profanity  Sensitive Topics   \n",
       "699  Illegal Drugs/Tobacco/eCigarettes/ Vaping/Alcohol  Sensitive Topics   \n",
       "700                            Spam or Harmful Content  Sensitive Topics   \n",
       "701                                          Terrorism  Sensitive Topics   \n",
       "702                    Debated Sensitive Social Issues  Sensitive Topics   \n",
       "\n",
       "               Tier 2             Tier 3 Tier 4  \n",
       "0                 NaN                NaN    NaN  \n",
       "1    Auto Body Styles                NaN    NaN  \n",
       "2    Auto Body Styles  Commercial Trucks    NaN  \n",
       "3    Auto Body Styles              Sedan    NaN  \n",
       "4    Auto Body Styles      Station Wagon    NaN  \n",
       "..                ...                ...    ...  \n",
       "698               NaN                NaN    NaN  \n",
       "699               NaN                NaN    NaN  \n",
       "700               NaN                NaN    NaN  \n",
       "701               NaN                NaN    NaN  \n",
       "702               NaN                NaN    NaN  \n",
       "\n",
       "[703 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f2376ddb56852a4ef860344626178ab373c7a1e5229e48d28a291855cf8ae81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aws_fastapi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
